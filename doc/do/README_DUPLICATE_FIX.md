# India Scraper â€” Quick Start

## âš ï¸ IMPORTANT: Fix Duplicate Data First!

The error you're seeing is because **existing data in the database has duplicates**, preventing the unique indexes from being created.

### ğŸ”§ One-Time Fix (Run This First)

```bash
cd d:\quad99\Scrappers
python scripts\India\fix_duplicates.py
```

This will:
1. âœ… Remove all duplicate rows from India tables
2. âœ… Create the required unique indexes
3. âœ… Verify everything is clean

**Expected output:**
```
============================================================
India: Fixing Duplicate Data
============================================================

Step 1: Checking for duplicates...
  in_sku_mrp: 123 duplicates found
  in_med_details: 45 duplicates found
  in_brand_alternatives: 678 duplicates found
  in_sku_main: 234 duplicates found

Step 2: Removing 1080 duplicate rows...
âœ“ Duplicates removed and indexes created successfully!

Step 3: Verifying fix...
  in_sku_mrp: Clean âœ“
  in_med_details: Clean âœ“
  in_brand_alternatives: Clean âœ“
  in_sku_main: Clean âœ“

============================================================
SUCCESS: All India tables are now duplicate-free!
You can now run the scraper without duplicate key errors.
============================================================
```

---

## ğŸš€ After Fixing Duplicates

### Run the Scraper

```bash
# Fresh run with 5 workers
python scripts\India\run_pipeline_scrapy.py --fresh --workers 5

# Resume interrupted run
python scripts\India\run_pipeline_scrapy.py --workers 5
```

---

## ğŸ“‹ What Changed?

The India scraper **already uses dedicated tables** with the `in_` prefix:
- `in_sku_main` â€” Main SKU data
- `in_sku_mrp` â€” MRP details
- `in_brand_alternatives` â€” Alternative brands
- `in_med_details` â€” Medicine details
- `in_formulation_status` â€” Work queue
- `in_input_formulations` â€” Input data

**These tables are India-specific and separate from other countries.**

The issue was that:
1. Old runs created duplicate data (before the duplicate prevention fix)
2. The unique indexes couldn't be created because duplicates existed
3. The fix script removes duplicates and creates the indexes

---

## âœ… Improvements Made

1. **Duplicate Prevention** â€” Fixed bug that allowed duplicates
2. **Circuit Breaker** â€” Pauses when NPPA API is down
3. **DB Reconnection** â€” Auto-reconnects on network failures
4. **Crash Logging** â€” Saves crash details to `crash_log.json`
5. **Performance** â€” 5-10x faster batch writes with `execute_values`
6. **Transaction Safety** â€” Atomic writes per formulation with savepoints

See `IMPROVEMENT_PLAN.md` for full details.

---

## ğŸ› Still Having Issues?

1. **Check the crash log**: `output\India\crash_log.json`
2. **Check worker logs**: `output\India\logs\worker_*.log`
3. **Verify database connection**: Run `python scripts\India\health_check.py`

---

**Questions? Check `IMPROVEMENT_PLAN.md` for detailed documentation.**
