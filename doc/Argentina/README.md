# Argentina Scraper Documentation

## Overview

The Argentina scraper extracts pharmaceutical product information from AlfaBeta (alfabeta.net), including product lists, pricing, and company details. The scraper processes data through multiple stages: extraction, translation, and final report generation.

## Workflow

The Argentina scraper follows a 6-step pipeline:

1. **00_backup_and_clean.py** - Backup existing output and clean for fresh run
2. **01_getProdList.py** - Extract product list from AlfaBeta
3. **02_alfabeta_scraper_labs.py** - Scrape detailed product information
4. **03_TranslateUsingDictionary.py** - Translate Spanish text to English
5. **04_GenerateOutput.py** - Generate final output report with PCID mapping
6. **05_PCIDmissing.py** - Process missing PCID entries

## Configuration

All configuration is managed through `config/Argentina.env.json`. The configuration follows the Malaysia format with script-specific prefixes:

- **SCRIPT_00_*** - Backup and clean configuration
- **SCRIPT_01_*** - Product list extraction settings
- **SCRIPT_02_*** - Main scraping configuration (threads, rate limits, API keys)
- **SCRIPT_03_*** - Translation settings
- **SCRIPT_04_*** - Output generation settings
- **SCRIPT_05_*** - PCID missing processing

### Key Configuration Values

- `ALFABETA_USER` / `ALFABETA_PASS` - AlfaBeta login credentials (in secrets section)
- `SCRAPINGDOG_API_KEY` - API key for ScrapingDog proxy service
- `HEADLESS` - Run browser in headless mode (default: false)
- `MAX_ROWS` - Maximum number of products to process (default: 100)
- `DEFAULT_THREADS` - Number of concurrent threads (default: 2)
- `RATE_LIMIT_PRODUCTS` / `RATE_LIMIT_SECONDS` - Rate limiting configuration

## Input Files

Place the following files in the input directory (`Input/`):

- `Dictionary.csv` - Spanish to English translation dictionary
- `pcid_Mapping.csv` - PCID mapping file
- `Productlist.csv` - Product list (generated by step 01)
- `ProxyList.txt` - Optional proxy list file

## Output Files

The scraper generates the following output files in the output directory:

- `Productlist.csv` - Extracted product list
- `alfabeta_products_by_product.csv` - Scraped product details
- `alfabeta_products_all_dict_en.csv` - Translated product data
- `alfabeta_Report_YYYYMMDD.csv` - Final output report with PCID mapping
- `pcid_MISSING.xlsx` - Products with missing PCID mappings

## Running the Scraper

### Using the GUI

1. Launch `scraper_gui.py`
2. Select "Argentina" from the scraper dropdown
3. Click "Run Pipeline" to execute all steps sequentially

### Using Command Line

Navigate to `scripts/Argentina/` and run:

```batch
run_pipeline.bat
```

Or run individual steps:

```bash
python 00_backup_and_clean.py
python 01_getProdList.py
python 02_alfabeta_scraper_labs.py
python 03_TranslateUsingDictionary.py
python 04_GenerateOutput.py
python 05_PCIDmissing.py
```

## Script Details

### 01_getProdList.py

Extracts product list from AlfaBeta website.

**Input:** None (scrapes from website)
**Output:** `Productlist.csv`

**Configuration:**
- `SCRIPT_01_PRODUCTS_URL` - AlfaBeta products URL
- `SCRIPT_01_HUB_URL` - AlfaBeta hub URL
- `SCRIPT_01_HEADLESS` - Browser headless mode

### 02_alfabeta_scraper_labs.py

Main scraping script that extracts detailed product information.

**Input:** `Productlist.csv`
**Output:** 
- `alfabeta_products_by_product.csv` - Product details
- `alfabeta_progress.csv` - Progress tracking
- `alfabeta_errors.csv` - Error log

**Configuration:**
- `SCRIPT_02_DEFAULT_THREADS` - Number of concurrent threads
- `SCRIPT_02_RATE_LIMIT_PRODUCTS` - Rate limit per product
- `SCRIPT_02_RATE_LIMIT_SECONDS` - Rate limit time window
- `SCRIPT_02_SCRAPINGDOG_URL` - ScrapingDog API URL
- `SCRIPT_02_MAX_ROWS` - Maximum rows to process

**Features:**
- Multi-threaded scraping
- Proxy support via ScrapingDog
- Account rotation
- Rate limiting
- Progress tracking
- Error logging

### 03_TranslateUsingDictionary.py

Translates Spanish text to English using a dictionary file.

**Input:** 
- `alfabeta_products_by_product.csv`
- `Dictionary.csv`

**Output:**
- `alfabeta_products_all_dict_en.csv` - Translated data
- `missing_cells.csv` - Cells that couldn't be translated

### 04_GenerateOutput.py

Generates final output report with PCID mapping.

**Input:**
- `alfabeta_products_all_dict_en.csv`
- `pcid_Mapping.csv`

**Output:**
- `alfabeta_Report_YYYYMMDD.csv` - Final report

**Features:**
- PCID mapping
- Data standardization
- Date-based file naming

### 05_PCIDmissing.py

Processes products with missing PCID mappings.

**Input:** Final report CSV
**Output:** `pcid_MISSING.xlsx`

## Troubleshooting

### Common Issues

1. **Login Failures**
   - Verify `ALFABETA_USER` and `ALFABETA_PASS` in config
   - Check if credentials are still valid

2. **Rate Limiting**
   - Adjust `RATE_LIMIT_PRODUCTS` and `RATE_LIMIT_SECONDS`
   - Reduce `DEFAULT_THREADS` if getting blocked

3. **Translation Errors**
   - Ensure `Dictionary.csv` is up to date
   - Check `missing_cells.csv` for untranslated entries

4. **PCID Mapping Issues**
   - Verify `pcid_Mapping.csv` format
   - Check column names match expected format

## Dependencies

- Selenium WebDriver
- pandas
- openpyxl (for Excel output)
- Python 3.8+

## Notes

- The scraper uses ScrapingDog for proxy support
- Account rotation is implemented to avoid rate limits
- All configuration values are in `config/Argentina.env.json`
- Secrets (API keys, passwords) are stored in the `secrets` section of the config file

